{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Transforms\n",
    "# transformer=transforms.Compose([\n",
    "#     transforms.Resize((150,150)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "#     transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "#                         [0.5,0.5,0.5])\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define transformations for data augmentation and normalization\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.RandomVerticalFlip(),    # Randomly flip the image vertically\n",
    "    transforms.RandomRotation(degrees=30),  # Randomly rotate the image up to 30 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Randomly change brightness, contrast, saturation, and hue\n",
    "    transforms.RandomResizedCrop(size=(150, 150), scale=(0.8, 1.0), ratio=(0.75, 1.333)),  # Randomly crop a portion of the image and resize it\n",
    "    transforms.RandomGrayscale(p=0.1),  # Randomly convert the image to grayscale with probability 0.1\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),  # Randomly apply perspective transformation\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize the image with mean and standard deviation\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path=r\"C:\\Users\\rohin\\Desktop\\New folder (2)\\biomet_pattern_and_people_detection\\Task 2 DeepFakes Detection-20240228\\cropped_cannyApplication\\kev_data_aug\\train\"\n",
    "test_path=r\"C:\\Users\\rohin\\Desktop\\New folder (2)\\biomet_pattern_and_people_detection\\Task 2 DeepFakes Detection-20240228\\cropped_cannyApplication\\kev_data_aug\\test\"\n",
    "\n",
    "# DataLoader with data augmentation\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path, transform=transformer),\n",
    "    batch_size=8, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path, transform=transformer),\n",
    "    batch_size=8, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fake', 'real']\n"
     ]
    }
   ],
   "source": [
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Network\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (256,3,150,150)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (256,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (256,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (256,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (256,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        #self.fc=nn.Linear(in_features=200 * 200 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829 424\n"
     ]
    }
   ],
   "source": [
    "num_epochs=20\n",
    "#calculating the size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(4.8637) Train Accuracy: 0.74412247129579 Test Accuracy: 0.8207547169811321\n",
      "Epoch: 1 Train Loss: tensor(1.0995) Train Accuracy: 0.7873154729360307 Test Accuracy: 0.8466981132075472\n",
      "Epoch: 2 Train Loss: tensor(0.4536) Train Accuracy: 0.8190267905959541 Test Accuracy: 0.8726415094339622\n",
      "Epoch: 3 Train Loss: tensor(0.3357) Train Accuracy: 0.8671405139420448 Test Accuracy: 0.7877358490566038\n",
      "Epoch: 4 Train Loss: tensor(0.3305) Train Accuracy: 0.847457627118644 Test Accuracy: 0.875\n",
      "Epoch: 5 Train Loss: tensor(0.3305) Train Accuracy: 0.8578458173865501 Test Accuracy: 0.8584905660377359\n",
      "Epoch: 6 Train Loss: tensor(0.3212) Train Accuracy: 0.8633132859486058 Test Accuracy: 0.9080188679245284\n",
      "Epoch: 7 Train Loss: tensor(0.3324) Train Accuracy: 0.8578458173865501 Test Accuracy: 0.8349056603773585\n",
      "Epoch: 8 Train Loss: tensor(0.3044) Train Accuracy: 0.8665937670858392 Test Accuracy: 0.8820754716981132\n",
      "Epoch: 9 Train Loss: tensor(0.2967) Train Accuracy: 0.8715144887916895 Test Accuracy: 0.8372641509433962\n",
      "Epoch: 10 Train Loss: tensor(0.3067) Train Accuracy: 0.8775287042099508 Test Accuracy: 0.8231132075471698\n",
      "Epoch: 11 Train Loss: tensor(0.3206) Train Accuracy: 0.8578458173865501 Test Accuracy: 0.8537735849056604\n",
      "Epoch: 12 Train Loss: tensor(0.2818) Train Accuracy: 0.8813559322033898 Test Accuracy: 0.8797169811320755\n",
      "Epoch: 13 Train Loss: tensor(0.2976) Train Accuracy: 0.8742482230727173 Test Accuracy: 0.8584905660377359\n",
      "Epoch: 14 Train Loss: tensor(0.3059) Train Accuracy: 0.8775287042099508 Test Accuracy: 0.8915094339622641\n",
      "Epoch: 15 Train Loss: tensor(0.2906) Train Accuracy: 0.878622197922362 Test Accuracy: 0.8679245283018868\n",
      "Epoch: 16 Train Loss: tensor(0.3082) Train Accuracy: 0.8737014762165117 Test Accuracy: 0.8537735849056604\n",
      "Epoch: 17 Train Loss: tensor(0.2863) Train Accuracy: 0.8758884636413341 Test Accuracy: 0.8867924528301887\n",
      "Epoch: 18 Train Loss: tensor(0.2943) Train Accuracy: 0.8780754510661564 Test Accuracy: 0.8773584905660378\n",
      "Epoch: 19 Train Loss: tensor(0.2871) Train Accuracy: 0.8797156916347731 Test Accuracy: 0.8113207547169812\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'RGB_FE_01.model')\n",
    "        best_accuracy=test_accuracy\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
